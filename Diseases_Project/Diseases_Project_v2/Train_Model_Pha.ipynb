{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"id":"mtRQvKUhmhlv","executionInfo":{"status":"error","timestamp":1745278943403,"user_tz":-420,"elapsed":10804,"user":{"displayName":"Anh Pha Võ Văn","userId":"18095071787583306591"}},"outputId":"c3974668-8128-4ced-eb44-0bbfd6acca59"},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-520b346d4474>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mINPUT_DATA_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Diseases_Project/Diseases_Project_v2/Sugarcane_leafs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","\n","drive.mount(\"/content/drive\")\n","\n","INPUT_DATA_PATH = \"/content/drive/MyDrive/Diseases_Project/Diseases_Project_v2/Sugarcane_leafs\"\n","SPLIT_DATA_PATH = \"/content/drive/MyDrive/Diseases_Project/Diseases_Project_v2/Sugarcane_leafs_Split\"\n","folder_path = \"/content/drive/My Drive/Diseases_Project/Diseases_Project_v2\"\n","output_csv_file = \"Diseases_labels.csv\"\n","dataset_splits_file = \"dataset_splits.csv\"\n","accuracy_loss_file = \"train_accuracy_loss.png\"\n","save_model_file = \"disease_model.keras\"\n","label_mapping_file = \"class_mapping.json\"\n","confusion_matrix_file = \"confusion_matrix.png\"\n","\n","IMAGE_SIZE = [256] #, 128, 256, 512, 1028]\n","EPOCHS = [80] # [20, 50, 80]\n","BATCH_SIZE = [32, 64, 128]\n","DENSE_LAYER = [128, 256, 512]\n","LEARNING_RATE = [0.00001, 0.0001, 0.001]\n","\n","import os\n","import json\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n","\n","train_folder_path = os.path.join(SPLIT_DATA_PATH, \"train\")\n","val_folder_path = os.path.join(SPLIT_DATA_PATH, \"val\")\n","test_folder_path = os.path.join(SPLIT_DATA_PATH, \"test\")\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1.0 / 255,\n","    rotation_range=90,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    zoom_range=0.2,\n",")\n","\n","val_test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n","\n","def save_class_mapping(test_generator, label_mapping_path):\n","    # Extract class indices from test_generator\n","    class_indices = test_generator.class_indices  # {class_name: class_index}\n","\n","    # Reverse the mapping to create {class_index: class_name}\n","    label_mapping = {value: key for key, value in class_indices.items()}\n","\n","    # Save the mapping to a JSON file\n","    with open(label_mapping_path, \"w\") as f:\n","        json.dump(label_mapping, f, indent=4)  # Use indent for better readability\n","\n","    print(f\"Class mapping saved to {label_mapping_path}\")\n","\n","def build_model(image_size, dense_layer, test_generator, learning_rate):\n","    base_model = ResNet50(weights='imagenet',\n","                        include_top=False,\n","                        input_shape=(image_size, image_size, 3))\n","\n","    base_model.trainable = True\n","\n","    model = Sequential([\n","        base_model,\n","        GlobalAveragePooling2D(),\n","        Dropout(0.5),\n","        Dense(dense_layer, activation='relu'),\n","        Dropout(0.5),\n","        Dense(len(test_generator.class_indices), activation='softmax')\n","    ])\n","\n","    model.compile(optimizer=Adam(learning_rate=learning_rate),\n","                loss='categorical_crossentropy',\n","                metrics=['accuracy'])\n","    return model\n","\n","def plot_and_save_training_history(history, accuracy_loss_file):\n","    # Plot Accuracy\n","    plt.figure(figsize=(10, 5))  # Create a figure with defined size\n","    plt.subplot(1, 2, 1)  # 1 row, 2 columns, plot in the first position\n","    plt.plot(history.history['accuracy'], label='Train Accuracy')\n","    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n","    plt.title('Accuracy over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    # Plot Loss\n","    plt.subplot(1, 2, 2)  # Plot in the second position\n","    plt.plot(history.history['loss'], label='Train Loss')\n","    plt.plot(history.history['val_loss'], label='Validation Loss')\n","    plt.title('Loss over Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.savefig(accuracy_loss_file)  # Save accuracy plot\n","    print(f\"Accuracy plot saved as {accuracy_loss_file}\")\n","    plt.close()  # Close the figure to free memory\n","\n","def plot_model_confusion_matrix(model, test_gen, confusion_matrix_file):\n","    \"\"\"\n","    Generates predictions on test data, computes the confusion matrix,\n","    and displays a heatmap.\n","\n","    Parameters:\n","    - model: Trained Keras model.\n","    - test_gen: Keras test data generator (with shuffle=False).\n","\n","    Returns:\n","    - y_true, y_pred: Lists of true and predicted class indices.\n","    \"\"\"\n","    y_true = []\n","    y_pred = []\n","\n","    # Loop through the test generator to collect predictions\n","    for x_batch, y_batch in test_gen:\n","        preds = model.predict(x_batch, verbose=0)\n","        y_true.extend(np.argmax(y_batch, axis=1))     # Convert one-hot to class indices\n","        y_pred.extend(np.argmax(preds, axis=1))\n","\n","        # Stop when the full test set is covered\n","        if len(y_true) >= test_gen.samples:\n","            break\n","\n","    # Truncate to match number of samples exactly\n","    y_true = y_true[:test_gen.samples]\n","    y_pred = y_pred[:test_gen.samples]\n","\n","    # Get class label names\n","    class_labels = list(test_gen.class_indices.keys())\n","\n","    # Compute confusion matrix\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    # Plot the confusion matrix\n","    plt.figure(figsize=(6, 5))\n","    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n","                xticklabels=class_labels, yticklabels=class_labels)\n","    plt.title(\"Confusion Matrix (Unnormalized)\")\n","    plt.xlabel(\"Predicted Label\")\n","    plt.ylabel(\"True Label\")\n","    plt.tight_layout()\n","    plt.savefig(confusion_matrix_file)  # Save accuracy plot\n","    plt.close()  # Close the figure to free memory\n","\n","for image_size in IMAGE_SIZE:\n","    img_size = (image_size, image_size)\n","    for batch_size in BATCH_SIZE:\n","        train_generator = train_datagen.flow_from_directory(\n","            train_folder_path,\n","            target_size=img_size,\n","            batch_size=batch_size,\n","            class_mode=\"categorical\",\n","        )\n","\n","        val_generator = val_test_datagen.flow_from_directory(\n","            val_folder_path,\n","            target_size=img_size,\n","            batch_size=batch_size,\n","            class_mode=\"categorical\",\n","        )\n","\n","        test_generator = val_test_datagen.flow_from_directory(\n","            test_folder_path,\n","            target_size=img_size,\n","            batch_size=batch_size,\n","            class_mode=\"categorical\",\n","            shuffle=False,\n","        )\n","        for epoch in EPOCHS:\n","            for dense_layer in DENSE_LAYER:\n","                for learning_rate in LEARNING_RATE:\n","                    sub_folder_path = os.path.join(\n","                        f\"{image_size}x{image_size}_v2\",\n","                        f\"BATCH_{batch_size}-EPOCHS_{epoch}-DENSE_{dense_layer}-LEARNING_RATE_{learning_rate}\",\n","                    )\n","                    output_csv_path = os.path.join(\n","                        folder_path, sub_folder_path, output_csv_file\n","                    )\n","                    dataset_splits_path = os.path.join(\n","                        folder_path, sub_folder_path, dataset_splits_file\n","                    )\n","                    accuracy_loss_path = os.path.join(\n","                        folder_path, sub_folder_path, accuracy_loss_file\n","                    )\n","                    save_model_path = os.path.join(\n","                        folder_path, sub_folder_path, save_model_file\n","                    )\n","                    label_mapping_path = os.path.join(\n","                        folder_path, sub_folder_path, label_mapping_file\n","                    )\n","                    confusion_matrix_path = os.path.join(\n","                        folder_path, sub_folder_path, confusion_matrix_file\n","                    )\n","\n","                    new_folder = os.path.join(folder_path, sub_folder_path)\n","                    os.makedirs(new_folder, exist_ok=True)\n","\n","                    save_class_mapping(test_generator, label_mapping_path)\n","\n","                    model = build_model(image_size, dense_layer, test_generator, learning_rate)\n","                    history = model.fit(train_generator, validation_data=val_generator, epochs=epoch)\n","                    model.save(save_model_path)\n","\n","                    plot_and_save_training_history(history, accuracy_loss_path)\n","                    plot_model_confusion_matrix(model, test_generator, confusion_matrix_path)"]}]}